+++
title = "Integrating prosody in anticipatory language processing: how listeners adapt to unconventional prosodic cues"
# date = 2013-07-01T00:00:00
date = 2021-12-02
draft = false

# Authors. Comma separated list, e.g. `["Jesse A. Harris"]`.
authors = ["Chie Nakamura", "Jesse A. Harris", "Sun-Ah Jun"]

# Publication type.
# Legend:
# 0 = Uncategorized
# 1 = Conference paper
# 2 = Journal article
# 3 = Manuscript
# 4 = Report
# 5 = Book
# 6 = Book section
publication_types = ["2"]

# Publication name and optional abbreviated version.
publication = "*Language, Cognition and Neuroscience*"
# publication_short = "In *ICMEW*"

# Abstract and optional shortened version.
abstract = "A growing body of research suggests that language users integrate diverse sources of information in processing and adapt to the variability of language at multiple levels. In two visual-world paradigm studies, we explored whether listeners use prosody to predict a resolution to structures with a PP that is structurally ambiguous between a modifier and an instrument interpretation. The first study revealed that listeners predict a referent that is most compatible with the location of a prosodic boundary, casting anticipatory looks to the appropriate object even before the onset of a disambiguating word. The second study indicated that listeners failed to anticipate instrument resolutions when the prosody of non-experimental filler items was unconventional, even though experimental items remained identical to the first study. The results suggest that listeners adjust their predictive processing to the utility of prosodic information according to whether a speaker reliably conforms to the conventional use of prosody."
abstract_short = ""

# Featured image thumbnail (optional)
image_preview = ""

# Is this a selected publication? (true/false)
selected = true
featured = false


# Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's filename without extension.
#   E.g. `projects = ["deep-learning"]` references `content/project/deep-learning.md`.
#   Otherwise, set `projects = []`.
# projects = ["sluicing", "ellipsis"]

# Tags (optional).
#   Set `tags = []` for no tags, or use the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = ["prediction", "prosody", "attachment", "visual world"]

# Links (optional).
# url_pdf = "https://www.tandfonline.com/doi/full/10.1080/23273798.2021.2010778?src="
# url_preprint = "files/papers/all/JEP_Misperception_Preprint.pdf"
# url_code = "#"
# url_dataset = "#"
# url_project = "#"
# url_slides = "#"
# url_video = "#"
# url_poster = "#"
# url_source = "#"

# Custom links (optional).
#   Uncomment line below to enable. For multiple links, use the form `[{...}, {...}, {...}]`.
url_custom = [{name = "Publisher", url = "https://www.tandfonline.com/doi/full/10.1080/23273798.2021.2010778?src="}]

# Does this page contain LaTeX math? (true/false)
math = true

# Does this page require source code highlighting? (true/false)
highlight = true

# Featured image
# Place your image in the `static/img/` folder and reference its filename below, e.g. `image = "example.jpg"`.
# [header]
# image = "headers/bubbles-wide.jpg"
# caption = "My caption :smile:"

+++
